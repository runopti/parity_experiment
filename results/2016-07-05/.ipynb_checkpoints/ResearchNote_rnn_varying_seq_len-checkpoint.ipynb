{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#option_seq_len=3 #option_output_size=2 #option_batch_size=1 #option_loss_diff_eps=1e-07 #option_grad_clip=True #option_max_epoch=800 #option_hidden_size=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import getData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_input_data = getData.createInputData(n)\n",
    "test_target_data = getData.createTargetData(test_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(n, state, session, seq_len):                                                                                                                                                       \n",
    "    total_sum = 0\n",
    "    for i in range(n):\n",
    "        state = initial_state.eval()\n",
    "        x = getData.createInputData(seq_len)\n",
    "        x = np.asarray(x).reshape(1, seq_len)\n",
    "        y = getData.createTargetData(x[0])[-1]\n",
    "        y_target = np.zeros((1,2))\n",
    "        if y == 0: y_target[0][0] = 1\n",
    "        else: y_target[0][1] = 1\n",
    "        feed_dict={initial_state: state, data:x}\n",
    "        output_ = session.run(output, feed_dict=feed_dict)\n",
    "        #print(np.argmax(y_target))\n",
    "        #print(np.argmax(output_))\n",
    "        if np.argmax(y_target) == np.argmax(output_):\n",
    "            total_sum += 1\n",
    "    return (1.0 * total_sum / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'GraphDef' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-458f7508e9dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mgdef_g1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdef_g1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"weights:0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'GraphDef' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "g1 = tf.Graph()\n",
    "with g1.as_default():\n",
    "    with tf.Session() as sess:\n",
    "        new_saver = tf.train.import_meta_graph('./hidden-uni-vis-test-2016-07-07-09:10:05/my_model-0.meta')\n",
    "        new_saver.restore(sess, './hidden-uni-vis-test-2016-07-07-09:10:05/my_model-0')\n",
    "        # restore variables and placeholders\n",
    "        data = tf.get_collection('data')[0]\n",
    "        target = tf.get_collection('target')[0]\n",
    "        initial_state = tf.get_collection('initial_state')[0]\n",
    "        output = tf.get_collection('output')[0]\n",
    "        state = tf.get_collection('state')[0]\n",
    "\n",
    "        y = test_target_data[-1]                                                                                                                        \n",
    "        y_target = np.zeros((1,2))\n",
    "        if y == 0: y_target[0][0] = 1 \n",
    "        else: y_target[0][1] = 1 \n",
    "        #feed_dict = {}\n",
    "        #print(sess.run(output, feed_dict = {data: np.array(test_input_data).reshape(1,3), target: y_target}))\n",
    "        #print(calc_accuracy(100, initial_state, sess, seq_len = 3))\n",
    "        #print(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n",
    "        #print(g1._nodes_by_name.keys())\n",
    "        #for step in xrange(1000000):\n",
    "            #sess.run(train_op)\n",
    "\n",
    "gdef_g1 = g1.as_graph_def()\n",
    "print(gdef_g1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TO DO : I should check the validity of the above method (loading model etc.) with the model that achieved 100% trainign error. -> Was good.\n",
    "\n",
    "I should do the visualization. \n",
    "TO DO : In order to do the varying-time-steps experiment, I need to extract the trained variables and copy them into another new computational graph.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g2 = tf.Graph()\n",
    "with g2.as_default():\n",
    "    test_var = tf.Variable(np.repeat(5,6).reshape(2,3), name=\"test_var\")\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        sess.run(test_var)\n",
    "        var_list = []\n",
    "        for var in tf.trainable_variables():\n",
    "            vc = tf.constant(var.eval())\n",
    "            tf.assign(var, vc, name=\"assign_variables\")\n",
    "            #var_list.append(tf.assign(var, vc))\n",
    "            #tf.group(*var_list, name=\"assign_trained_variables\") \n",
    "        tf.train.write_graph(sess.graph_def, logdir=\"./\", name=\"test_graph.pbtxt\")\n",
    "        # g2.as_graph_def() and sess.graph_def are the same thing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "substring not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-e8ed809e3786>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mvalue_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\":\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: substring not found"
     ]
    }
   ],
   "source": [
    "from tensorflow.core.framework import graph_pb2\n",
    "from google.protobuf import text_format\n",
    "with open(\"test_graph.pbtxt\", \"rt\") as f: # rt not rb b/c it's a text file\n",
    "    graph_def = graph_pb2.GraphDef()\n",
    "    text_format.Merge(f.read(), graph_def)\n",
    "    #graph_def.ParseFromString(f.read)\n",
    "    a = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "    node = graph_def.node[0]\n",
    "    value_node = node.attr['value'].tensor\n",
    "    print(node.name\n",
    "\n",
    "    \n",
    "    \n",
    "    #with tf.Graph().as_default() as g2_2:\n",
    "        #tf.import_graph_def(graph_def, return_elements=)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test cell; I can delete this layer\n",
    "def f(x):\n",
    "    return tf.identity(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test cell; I can delete this later\n",
    "with tf.Graph().as_default() as g3:\n",
    "    input = tf.placeholder(tf.float32, name=\"input\")\n",
    "    y = f(input)\n",
    "    output = tf.identity(y, name=\"output\")\n",
    "\n",
    "gdef_1 = g3.as_graph_def()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test cell; I can delete this later\n",
    "def test():\n",
    "    with tf.Graph().as_default() as g4:\n",
    "        aa = tf.Variable(np.zeros([2,3]))\n",
    "        saver = tf.train.Saver()\n",
    "        print(saver.as_saver_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename_tensor_name: \"save/Const:0\"\n",
      "save_tensor_name: \"save/control_dependency:0\"\n",
      "restore_op_name: \"save/restore_all\"\n",
      "max_to_keep: 5\n",
      "keep_checkpoint_every_n_hours: 10000.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
